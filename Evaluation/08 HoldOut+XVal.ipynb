{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hold Out and Cross Validation compared\n",
    "The objective of this notebook is to illustrate the benefits of Cross Validation over Hold Out. \n",
    "1. In the first analysis we show how X Val estimates of accuracy are lower variance that Hold Out. This is done by repeating each analysis 100 times and plotting the results. \n",
    "2. In the second analysis we show how accuracy estimation varies with training set size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "dtree = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bcDB = datasets.load_breast_cancer()\n",
    "y = bcDB.target\n",
    "X = bcDB.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hold-Out Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reps = 100\n",
    "ho = []\n",
    "for i in range(reps):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i)\n",
    "    y_pred = dtree.fit(X_train, y_train).predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    ho.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## X Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xv = []\n",
    "for i in range(reps):\n",
    "    kf = KFold(n_splits=10, shuffle = True) # needed to ensure shuffling\n",
    "    scores = cross_val_score(dtree, X, y, cv=kf)\n",
    "    xv.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(ho, columns = ['Hold Out'])\n",
    "res['X Val']=xv\n",
    "%matplotlib inline\n",
    "ax = res.plot()\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy: Hold Out and X Val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Learning Curve\n",
    "In the second analysis we show how accuracy estimation varies with training set size.   \n",
    "We switch to the wine dataset because the effect is more evident there because it is a smaller dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wineDB = datasets.load_wine()\n",
    "y = wineDB.target\n",
    "X = wineDB.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "num = 30\n",
    "ho_s = []\n",
    "s_s = []\n",
    "for i in range(1,num):\n",
    "    s = i/num\n",
    "    for j in range(500):\n",
    "        ss =[]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = s)\n",
    "        y_pred = dtree.fit(X_train, y_train).predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        ss.append(acc)\n",
    "    ho_s.append(mean(ss))\n",
    "    s_s.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ho_s = pd.DataFrame(ho_s, index = s_s, columns = ['Hold Out'])\n",
    "ax = ho_s.plot()\n",
    "ax.set_xlabel(\"Train Set Proportion\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy: Train Set Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}